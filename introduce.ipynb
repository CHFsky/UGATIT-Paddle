{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 【GAN】Unsupervised Unsupervised Generative Attentional Networks with Adaptive Layer-Instance N 论文复现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![项目结构](https://ai-studio-static-online.cdn.bcebos.com/e70cfb45adf543ec8c572ea846cd23bd84c55ddeb4884231a3d8356cc32c66f7)\n",
    "- 上图为该项目的结构tree\n",
    "> data内data48778为挂在数据库，datasets为对应trainA，trainB，testA，testB的解压</br>\n",
    "\n",
    "> results存放对应名为datasets的结果文件夹，里面为自定义打印间隔存放训练示例图的img文件夹，每1000个iter存储一次模型的latest文件夹，固定间隔存储一次的model文件夹以及模型测试图片结果存放的test文件夹</br>\n",
    "\n",
    "> KID为论文作者给出的评估生成图像的代码\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 该项目若干步骤说明（共训练30.3W轮）</br>\n",
    "**tips:只保留了最新一次模型，但评估结果来自众多次保存模型中的最优者，因此给出了最优测试集生成结果，在result/datasets/test/路径下**</br>\n",
    "**tips:其余模型生成测试集的图片，在result/datasets/test/else/路径下**</br>\n",
    "\n",
    "1. 升级paddle版本：\n",
    "\t- !pip install paddlepaddle-gpu==1.8.3.post97\n",
    "2. 解压数据集：\n",
    "\t- !unzip -q /home/aistudio/data/data48778/308470_627400_bundle_archive.zip -d data/datasets/\n",
    "3. 生成训练集A，训练集B和测试集A，测试集B的txt路径文件：\n",
    "\t- !python genarate_txt.py\n",
    "4. 分别读取对应txt文件，进行初步的图像预处理，并输入进行训练，保存训练模型，存入results中datasets的model和latest文件夹：\n",
    "\t- !export LD_LIBRARY_PATH=/usr/local/cuda-9.2/lib64:$LD_LIBRARY_PATH && python main.py --dataset datasets --phase train --iteration 100000 --print_freq 1000 --save_freq 5000  --light True --resume False\n",
    "5. 生成测试集上的原图，注意力图，转换图等对比，存入test文件夹：\n",
    "\t- !export LD_LIBRARY_PATH=/usr/local/cuda-9.2/lib64:$LD_LIBRARY_PATH && python main.py --phase test\n",
    "6. 通过模型在测试集上进行对应的图像的生成，存入test中testA2B和testB2A文件夹：\n",
    "\t- !export LD_LIBRARY_PATH=/usr/local/cuda-9.2/lib64:$LD_LIBRARY_PATH && python main.py --phase test_change\n",
    "7. 评估KID(由论文作者的tensorflow代码给出)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 评估A2B的KID结果（10.47±0.39）生成图见results的test文件夹内的A2B\n",
    "\n",
    "**KID_mean :  5.79439289867877**</br>\n",
    "**KID_stddev :  0.372276245616376**</br>\n",
    "WARNING:tensorflow:From C:\\Users\\54406\\Desktop\\GAN_Metrics-Tensorflow-master\\frechet_kernel_Inception_distance.py:128: to_double (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
    "Instructions for updating:\n",
    "Use `tf.cast` instead.\n",
    "WARNING:tensorflow:From C:\\Users\\54406\\Desktop\\GAN_Metrics-Tensorflow-master\\frechet_kernel_Inception_distance.py:36: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
    "Instructions for updating:\n",
    "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
    "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000028BBF19D848>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000028BBF19D848>>: AttributeError: module 'gast' has no attribute 'Index'\n",
    "</br>\n",
    "**mean_FID :  1.28803382568359**</br>\n",
    "**mean_KID_mean :  10.4690839387476**</br>\n",
    "**mean_KID_stddev :  0.390721662668511**</br>\n",
    "\n",
    "tips: 生成器的1X1卷积，以及判别器的bias=True的卷积处：bias的初始化用了kaiming初始化，paddle默认bias为全0初始化，对于这一点改进，应该对结果有提升"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 评估B2A的KID结果（12.26±0.36）生成图见results的test文件夹内的B2A\n",
    "\n",
    "**KID_mean :  9.53569784760475**</br>\n",
    "**KID_stddev :  0.513339787721633**</br>\n",
    "WARNING:tensorflow:From C:\\Users\\54406\\Desktop\\GAN_Metrics-Tensorflow-master\\frechet_kernel_Inception_distance.py:128: to_double (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating: Use tf.cast instead. WARNING:tensorflow:From C:\\Users\\54406\\Desktop\\GAN_Metrics-Tensorflow-master\\frechet_kernel_Inception_distance.py:36: add_dispatch_support..wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version. Instructions for updating: Use tf.where in 2.0, which has the same broadcast rule as np.where WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000028BBF19D848>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, export AUTOGRAPH_VERBOSITY=10) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000028BBF19D848>>: AttributeError: module 'gast' has no attribute 'Index'</br>\n",
    "**mean_FID :  1.35143750305175**</br>\n",
    "**mean_KID_mean :  12.2581704035401**</br>\n",
    "**mean_KID_stddev :  0.357183634769171**</br>\n",
    "\n",
    "tips: 生成器的1X1卷积，以及判别器的bias=True的卷积处：bias的初始化用了kaiming初始化，paddle默认bias为全0初始化，对于这一点改进，应该对结果有提升"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 训练过程\n",
    "1. 20w-22w轮</br>\n",
    "![训练过程](https://ai-studio-static-online.cdn.bcebos.com/0bb2fc7996ee45efb237a85c0715f303548eb192de6e4ef8a48c8e65640b9968)\n",
    "2. 20-22w训练示意图</br>\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/6db0ec74e62b4acf842a0036780739ecfeb03f6f1b884db5acd639de87860172)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 测试过程\n",
    "1.测试生成图片示例</br>\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/eede7790b475437794422939e2c9df6d08c15d5272954398bf1a32cbdabb3738)</br>\n",
    "2.测试图片转换示例</br>\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/600f50e5755f4b7abef630c2d4de5f4abb696bfc40d946bf84a82d68c6acfba4)</br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 主体代码\r\n",
    "# 包含训练，测试\r\n",
    "from dataset import *\r\n",
    "\r\n",
    "import transforms\r\n",
    "import time\r\n",
    "import os\r\n",
    "from networks import ResnetGenerator,Discriminator\r\n",
    "from utils import denorm,tensor2numpy,RGB2BGR,cam,BCEWithLogitsLoss,RhoClipper\r\n",
    "from paddle.fluid.layers import ones_like,zeros_like\r\n",
    "import paddle.fluid as fluid\r\n",
    "from paddle.fluid.dygraph import L1Loss,MSELoss,to_variable\r\n",
    "import numpy as np\r\n",
    "import cv2\r\n",
    "import paddle\r\n",
    "\r\n",
    "DATASET = \"datasets\"\r\n",
    "A_TEST_LIST_FILE = \"data/\" + DATASET + \"/testA.txt\"\r\n",
    "B_TEST_LIST_FILE = \"data/\" + DATASET + \"/testB.txt\"\r\n",
    "IMAGES_ROOT = \"data/\" + DATASET + \"/\"\r\n",
    "\r\n",
    "\r\n",
    "class UGATIT(object):\r\n",
    "    def __init__(self, args):\r\n",
    "        self.light = args.light\r\n",
    "\r\n",
    "        if self.light:\r\n",
    "            self.model_name = 'UGATIT_light'\r\n",
    "        else:\r\n",
    "            self.model_name = 'UGATIT'\r\n",
    "\r\n",
    "        self.result_dir = args.result_dir\r\n",
    "        self.dataset = args.dataset\r\n",
    "\r\n",
    "        self.iteration = args.iteration\r\n",
    "        self.decay_flag = args.decay_flag\r\n",
    "\r\n",
    "        self.batch_size = args.batch_size\r\n",
    "        self.print_freq = args.print_freq\r\n",
    "        self.save_freq = args.save_freq\r\n",
    "\r\n",
    "        self.lr = args.lr\r\n",
    "        self.weight_decay = args.weight_decay\r\n",
    "        self.ch = args.ch\r\n",
    "\r\n",
    "        \"\"\" Weight \"\"\"\r\n",
    "        self.adv_weight = args.adv_weight\r\n",
    "        self.cycle_weight = args.cycle_weight\r\n",
    "        self.identity_weight = args.identity_weight\r\n",
    "        self.cam_weight = args.cam_weight\r\n",
    "\r\n",
    "        \"\"\" Generator \"\"\"\r\n",
    "        self.n_res = args.n_res\r\n",
    "\r\n",
    "        \"\"\" Discriminator \"\"\"\r\n",
    "        self.n_dis = args.n_dis\r\n",
    "\r\n",
    "        self.img_size = args.img_size\r\n",
    "        self.img_ch = args.img_ch\r\n",
    "\r\n",
    "        self.resume = args.resume\r\n",
    "\r\n",
    "\r\n",
    "    ##################################################################################\r\n",
    "    # Model\r\n",
    "    ##################################################################################\r\n",
    "    def optimizer_setting(self,parameters):\r\n",
    "        lr = 0.0001\r\n",
    "        optimizer = fluid.optimizer.Adam(\r\n",
    "            learning_rate=lr,\r\n",
    "            parameter_list=parameters,\r\n",
    "            beta1=0.5, beta2=0.999, regularization=fluid.regularizer.L2Decay(self.weight_decay))\r\n",
    "        return optimizer\r\n",
    "\r\n",
    "    def build_model(self):\r\n",
    "        \"\"\" DataLoader \"\"\"\r\n",
    "        train_transform = transforms.Compose([\r\n",
    "            transforms.RandomHorizontalFlip(),\r\n",
    "            transforms.Resize((self.img_size + 30, self.img_size + 30)),\r\n",
    "            transforms.RandomCrop(self.img_size),\r\n",
    "            transforms.ToTensor(),\r\n",
    "            transforms.Normalize(mean=0.5, std=0.5)\r\n",
    "        ])\r\n",
    "        test_transform = transforms.Compose([\r\n",
    "            transforms.Resize((self.img_size, self.img_size)),\r\n",
    "            transforms.ToTensor(),\r\n",
    "            transforms.Normalize(mean=0.5, std=0.5)\r\n",
    "        ])\r\n",
    "        self.trainA_loader = paddle.batch(a_reader(shuffle=True,transforms=train_transform), self.batch_size)()\r\n",
    "        self.trainB_loader = paddle.batch(b_reader(shuffle=True,transforms=train_transform), self.batch_size)()\r\n",
    "        self.testA_loader = a_test_reader(transforms=test_transform)\r\n",
    "        self.testB_loader = b_test_reader(transforms=test_transform)\r\n",
    "\r\n",
    "\r\n",
    "        \"\"\" Define Generator, Discriminator \"\"\"\r\n",
    "        self.genA2B = ResnetGenerator(input_nc=3, output_nc=3, ngf=self.ch, n_blocks=self.n_res, img_size=self.img_size,\r\n",
    "                                      light=self.light)\r\n",
    "        self.genB2A = ResnetGenerator(input_nc=3, output_nc=3, ngf=self.ch, n_blocks=self.n_res, img_size=self.img_size,\r\n",
    "                                      light=self.light)\r\n",
    "        self.disGA = Discriminator(input_nc=3, ndf=self.ch, n_layers=7)\r\n",
    "        self.disGB = Discriminator(input_nc=3, ndf=self.ch, n_layers=7)\r\n",
    "        self.disLA = Discriminator(input_nc=3, ndf=self.ch, n_layers=5)\r\n",
    "        self.disLB = Discriminator(input_nc=3, ndf=self.ch, n_layers=5)\r\n",
    "\r\n",
    "        \"\"\" Define Loss \"\"\"\r\n",
    "        self.L1_loss = L1Loss()\r\n",
    "        self.MSE_loss = MSELoss()\r\n",
    "        self.BCE_loss = BCEWithLogitsLoss()\r\n",
    "\r\n",
    "        \"\"\" Trainer \"\"\"\r\n",
    "        self.G_optim = self.optimizer_setting(self.genA2B.parameters() + self.genB2A.parameters())\r\n",
    "        self.D_optim = self.optimizer_setting(self.disGA.parameters() + self.disGB.parameters() + self.disLA.parameters() + self.disLB.parameters())\r\n",
    "\r\n",
    "        \"\"\" Define Rho clipper to constraint the value of rho in AdaILN and ILN\"\"\"\r\n",
    "        self.Rho_clipper = RhoClipper(0, 1)\r\n",
    "\r\n",
    "    def train(self):\r\n",
    "        self.genA2B.train(), self.genB2A.train(), self.disGA.train(), self.disGB.train(), self.disLA.train(), self.disLB.train()\r\n",
    "\r\n",
    "        start_iter = 1\r\n",
    "        if self.resume:\r\n",
    "            model_list = os.listdir(os.path.join(self.result_dir, self.dataset, 'model'))\r\n",
    "            if not len(model_list) == 0:\r\n",
    "                model_list.sort()\r\n",
    "                iter = int(model_list[-1])\r\n",
    "                print(\"[*]load %d\"%(iter))\r\n",
    "                self.load(os.path.join(self.result_dir, self.dataset, 'model'), iter)\r\n",
    "                print(\"[*] Load SUCCESS\")\r\n",
    "\r\n",
    "        # training loop\r\n",
    "        print('training start !')\r\n",
    "        start_time = time.time()\r\n",
    "        for step in range(start_iter, self.iteration + 1):\r\n",
    "            real_A = next(self.trainA_loader)\r\n",
    "            real_B = next(self.trainB_loader)\r\n",
    "            real_A = np.array([real_A[0].reshape(3, 256, 256)]).astype(\"float32\")\r\n",
    "            real_B = np.array([real_B[0].reshape(3, 256, 256)]).astype(\"float32\")\r\n",
    "            real_A = to_variable(real_A)\r\n",
    "            real_B = to_variable(real_B)\r\n",
    "            # Update D\r\n",
    "            \r\n",
    "            fake_A2B, _, _ = self.genA2B(real_A)\r\n",
    "            fake_B2A, _, _ = self.genB2A(real_B)\r\n",
    "\r\n",
    "            real_GA_logit, real_GA_cam_logit, _ = self.disGA(real_A)\r\n",
    "            real_LA_logit, real_LA_cam_logit, _ = self.disLA(real_A)\r\n",
    "            real_GB_logit, real_GB_cam_logit, _ = self.disGB(real_B)\r\n",
    "            real_LB_logit, real_LB_cam_logit, _ = self.disLB(real_B)\r\n",
    "\r\n",
    "            fake_GA_logit, fake_GA_cam_logit, _ = self.disGA(fake_B2A)\r\n",
    "            fake_LA_logit, fake_LA_cam_logit, _ = self.disLA(fake_B2A)\r\n",
    "            fake_GB_logit, fake_GB_cam_logit, _ = self.disGB(fake_A2B)\r\n",
    "            fake_LB_logit, fake_LB_cam_logit, _ = self.disLB(fake_A2B)\r\n",
    "\r\n",
    "            D_ad_loss_GA = self.MSE_loss(real_GA_logit, ones_like(real_GA_logit)) + self.MSE_loss(fake_GA_logit,\r\n",
    "                                                                                                    zeros_like(\r\n",
    "                                                                                                        fake_GA_logit))\r\n",
    "            D_ad_cam_loss_GA = self.MSE_loss(real_GA_cam_logit, ones_like(real_GA_cam_logit)) + self.MSE_loss(\r\n",
    "                fake_GA_cam_logit, zeros_like(fake_GA_cam_logit))\r\n",
    "            D_ad_loss_LA = self.MSE_loss(real_LA_logit, ones_like(real_LA_logit)) + self.MSE_loss(fake_LA_logit,\r\n",
    "                                                                                                    zeros_like(\r\n",
    "                                                                                                        fake_LA_logit))\r\n",
    "            D_ad_cam_loss_LA = self.MSE_loss(real_LA_cam_logit, ones_like(real_LA_cam_logit)) + self.MSE_loss(\r\n",
    "                fake_LA_cam_logit, zeros_like(fake_LA_cam_logit))\r\n",
    "            D_ad_loss_GB = self.MSE_loss(real_GB_logit, ones_like(real_GB_logit)) + self.MSE_loss(fake_GB_logit,\r\n",
    "                                                                                                    zeros_like(\r\n",
    "                                                                                                        fake_GB_logit))\r\n",
    "            D_ad_cam_loss_GB = self.MSE_loss(real_GB_cam_logit, ones_like(real_GB_cam_logit)) + self.MSE_loss(\r\n",
    "                fake_GB_cam_logit, zeros_like(fake_GB_cam_logit))\r\n",
    "            D_ad_loss_LB = self.MSE_loss(real_LB_logit, ones_like(real_LB_logit)) + self.MSE_loss(fake_LB_logit,\r\n",
    "                                                                                                    zeros_like(\r\n",
    "                                                                                                        fake_LB_logit))\r\n",
    "            D_ad_cam_loss_LB = self.MSE_loss(real_LB_cam_logit, ones_like(real_LB_cam_logit)) + self.MSE_loss(\r\n",
    "                fake_LB_cam_logit, zeros_like(fake_LB_cam_logit))\r\n",
    "\r\n",
    "            D_loss_A = self.adv_weight * (D_ad_loss_GA + D_ad_cam_loss_GA + D_ad_loss_LA + D_ad_cam_loss_LA)\r\n",
    "            D_loss_B = self.adv_weight * (D_ad_loss_GB + D_ad_cam_loss_GB + D_ad_loss_LB + D_ad_cam_loss_LB)\r\n",
    "\r\n",
    "            Discriminator_loss = D_loss_A + D_loss_B\r\n",
    "            Discriminator_loss.backward()\r\n",
    "            self.D_optim.minimize(Discriminator_loss)\r\n",
    "            self.genB2A.clear_gradients()\r\n",
    "            self.genA2B.clear_gradients()\r\n",
    "            self.disGA.clear_gradients()\r\n",
    "            self.disLA.clear_gradients()\r\n",
    "            self.disGB.clear_gradients()\r\n",
    "            self.disLB.clear_gradients()\r\n",
    "            self.D_optim.clear_gradients()\r\n",
    "\r\n",
    "            # Update G\r\n",
    "\r\n",
    "\r\n",
    "            fake_A2B, fake_A2B_cam_logit, _ = self.genA2B(real_A)\r\n",
    "            fake_B2A, fake_B2A_cam_logit, _ = self.genB2A(real_B)\r\n",
    "\r\n",
    "            fake_A2B2A, _, _ = self.genB2A(fake_A2B)\r\n",
    "            fake_B2A2B, _, _ = self.genA2B(fake_B2A)\r\n",
    "\r\n",
    "            fake_A2A, fake_A2A_cam_logit, _ = self.genB2A(real_A)\r\n",
    "            fake_B2B, fake_B2B_cam_logit, _ = self.genA2B(real_B)\r\n",
    "\r\n",
    "            fake_GA_logit, fake_GA_cam_logit, _ = self.disGA(fake_B2A)\r\n",
    "            fake_LA_logit, fake_LA_cam_logit, _ = self.disLA(fake_B2A)\r\n",
    "            fake_GB_logit, fake_GB_cam_logit, _ = self.disGB(fake_A2B)\r\n",
    "            fake_LB_logit, fake_LB_cam_logit, _ = self.disLB(fake_A2B)\r\n",
    "\r\n",
    "            G_ad_loss_GA = self.MSE_loss(fake_GA_logit, ones_like(fake_GA_logit))\r\n",
    "            G_ad_cam_loss_GA = self.MSE_loss(fake_GA_cam_logit, ones_like(fake_GA_cam_logit))\r\n",
    "            G_ad_loss_LA = self.MSE_loss(fake_LA_logit, ones_like(fake_LA_logit))\r\n",
    "            G_ad_cam_loss_LA = self.MSE_loss(fake_LA_cam_logit, ones_like(fake_LA_cam_logit))\r\n",
    "            G_ad_loss_GB = self.MSE_loss(fake_GB_logit, ones_like(fake_GB_logit))\r\n",
    "            G_ad_cam_loss_GB = self.MSE_loss(fake_GB_cam_logit, ones_like(fake_GB_cam_logit))\r\n",
    "            G_ad_loss_LB = self.MSE_loss(fake_LB_logit, ones_like(fake_LB_logit))\r\n",
    "            G_ad_cam_loss_LB = self.MSE_loss(fake_LB_cam_logit, ones_like(fake_LB_cam_logit))\r\n",
    "\r\n",
    "            G_recon_loss_A = self.L1_loss(fake_A2B2A, real_A)\r\n",
    "            G_recon_loss_B = self.L1_loss(fake_B2A2B, real_B)\r\n",
    "\r\n",
    "            G_identity_loss_A = self.L1_loss(fake_A2A, real_A)\r\n",
    "            G_identity_loss_B = self.L1_loss(fake_B2B, real_B)\r\n",
    "\r\n",
    "            G_cam_loss_A = self.BCE_loss(fake_B2A_cam_logit,\r\n",
    "                                            ones_like(fake_B2A_cam_logit)) + self.BCE_loss(\r\n",
    "                fake_A2A_cam_logit, zeros_like(fake_A2A_cam_logit))\r\n",
    "            G_cam_loss_B = self.BCE_loss(fake_A2B_cam_logit,\r\n",
    "                                            ones_like(fake_A2B_cam_logit)) + self.BCE_loss(\r\n",
    "                fake_B2B_cam_logit, zeros_like(fake_B2B_cam_logit))\r\n",
    "\r\n",
    "            G_loss_A = self.adv_weight * (\r\n",
    "                        G_ad_loss_GA + G_ad_cam_loss_GA + G_ad_loss_LA + G_ad_cam_loss_LA) + self.cycle_weight * G_recon_loss_A + self.identity_weight * G_identity_loss_A + self.cam_weight * G_cam_loss_A\r\n",
    "            G_loss_B = self.adv_weight * (\r\n",
    "                        G_ad_loss_GB + G_ad_cam_loss_GB + G_ad_loss_LB + G_ad_cam_loss_LB) + self.cycle_weight * G_recon_loss_B + self.identity_weight * G_identity_loss_B + self.cam_weight * G_cam_loss_B\r\n",
    "\r\n",
    "            Generator_loss = G_loss_A + G_loss_B\r\n",
    "            Generator_loss.backward()\r\n",
    "            self.G_optim.minimize(Generator_loss)\r\n",
    "            self.genB2A.clear_gradients()\r\n",
    "            self.genA2B.clear_gradients()\r\n",
    "            self.disGA.clear_gradients()\r\n",
    "            self.disLA.clear_gradients()\r\n",
    "            self.disGB.clear_gradients()\r\n",
    "            self.disLB.clear_gradients()\r\n",
    "            self.G_optim.clear_gradients()\r\n",
    "\r\n",
    "            self.Rho_clipper(self.genA2B)\r\n",
    "            self.Rho_clipper(self.genB2A)\r\n",
    "\r\n",
    "            print(\"[%5d/%5d] time: %4.4f d_loss: %.8f, g_loss: %.8f\" % (step, self.iteration, time.time() - start_time, Discriminator_loss, Generator_loss))\r\n",
    "\r\n",
    "            if step % self.print_freq == 0:\r\n",
    "                train_sample_num = 5\r\n",
    "                test_sample_num = 5\r\n",
    "                A2B = np.zeros((self.img_size * 7, 0, 3))\r\n",
    "                B2A = np.zeros((self.img_size * 7, 0, 3))\r\n",
    "\r\n",
    "                self.genA2B.eval(), self.genB2A.eval(), self.disGA.eval(), self.disGB.eval(), self.disLA.eval(), self.disLB.eval()\r\n",
    "                for _ in range(train_sample_num):\r\n",
    "                    real_A = next(self.trainA_loader)\r\n",
    "                    real_B = next(self.trainB_loader)\r\n",
    "                    real_A = np.array([real_A[0].reshape(3, 256, 256)]).astype(\"float32\")\r\n",
    "                    real_B = np.array([real_B[0].reshape(3, 256, 256)]).astype(\"float32\")\r\n",
    "                    real_A = to_variable(real_A)\r\n",
    "                    real_B = to_variable(real_B)\r\n",
    "\r\n",
    "                    fake_A2B, _, fake_A2B_heatmap = self.genA2B(real_A)\r\n",
    "                    fake_B2A, _, fake_B2A_heatmap = self.genB2A(real_B)\r\n",
    "\r\n",
    "                    fake_A2B2A, _, fake_A2B2A_heatmap = self.genB2A(fake_A2B)\r\n",
    "                    fake_B2A2B, _, fake_B2A2B_heatmap = self.genA2B(fake_B2A)\r\n",
    "\r\n",
    "                    fake_A2A, _, fake_A2A_heatmap = self.genB2A(real_A)\r\n",
    "                    fake_B2B, _, fake_B2B_heatmap = self.genA2B(real_B)\r\n",
    "\r\n",
    "                    A2B = np.concatenate((A2B, np.concatenate((RGB2BGR(tensor2numpy(denorm(real_A[0]))),\r\n",
    "                                                                cam(tensor2numpy(fake_A2A_heatmap[0]), self.img_size),\r\n",
    "                                                                RGB2BGR(tensor2numpy(denorm(fake_A2A[0]))),\r\n",
    "                                                                cam(tensor2numpy(fake_A2B_heatmap[0]), self.img_size),\r\n",
    "                                                                RGB2BGR(tensor2numpy(denorm(fake_A2B[0]))),\r\n",
    "                                                                cam(tensor2numpy(fake_A2B2A_heatmap[0]), self.img_size),\r\n",
    "                                                                RGB2BGR(tensor2numpy(denorm(fake_A2B2A[0])))), 0)), 1)\r\n",
    "\r\n",
    "                    B2A = np.concatenate((B2A, np.concatenate((RGB2BGR(tensor2numpy(denorm(real_B[0]))),\r\n",
    "                                                                cam(tensor2numpy(fake_B2B_heatmap[0]), self.img_size),\r\n",
    "                                                                RGB2BGR(tensor2numpy(denorm(fake_B2B[0]))),\r\n",
    "                                                                cam(tensor2numpy(fake_B2A_heatmap[0]), self.img_size),\r\n",
    "                                                                RGB2BGR(tensor2numpy(denorm(fake_B2A[0]))),\r\n",
    "                                                                cam(tensor2numpy(fake_B2A2B_heatmap[0]), self.img_size),\r\n",
    "                                                                RGB2BGR(tensor2numpy(denorm(fake_B2A2B[0])))), 0)), 1)\r\n",
    "\r\n",
    "                for _ in range(test_sample_num):\r\n",
    "                    real_A = next(self.testA_loader())\r\n",
    "                    real_B = next(self.testB_loader())\r\n",
    "                    real_A = np.array([real_A[0].reshape(3, 256, 256)]).astype(\"float32\")\r\n",
    "                    real_B = np.array([real_B[0].reshape(3, 256, 256)]).astype(\"float32\")\r\n",
    "                    real_A = to_variable(real_A)\r\n",
    "                    real_B = to_variable(real_B)\r\n",
    "\r\n",
    "                    fake_A2B, _, fake_A2B_heatmap = self.genA2B(real_A)\r\n",
    "                    fake_B2A, _, fake_B2A_heatmap = self.genB2A(real_B)\r\n",
    "\r\n",
    "                    fake_A2B2A, _, fake_A2B2A_heatmap = self.genB2A(fake_A2B)\r\n",
    "                    fake_B2A2B, _, fake_B2A2B_heatmap = self.genA2B(fake_B2A)\r\n",
    "\r\n",
    "                    fake_A2A, _, fake_A2A_heatmap = self.genB2A(real_A)\r\n",
    "                    fake_B2B, _, fake_B2B_heatmap = self.genA2B(real_B)\r\n",
    "\r\n",
    "                    A2B = np.concatenate((A2B, np.concatenate((RGB2BGR(tensor2numpy(denorm(real_A[0]))),\r\n",
    "                                                                cam(tensor2numpy(fake_A2A_heatmap[0]), self.img_size),\r\n",
    "                                                                RGB2BGR(tensor2numpy(denorm(fake_A2A[0]))),\r\n",
    "                                                                cam(tensor2numpy(fake_A2B_heatmap[0]), self.img_size),\r\n",
    "                                                                RGB2BGR(tensor2numpy(denorm(fake_A2B[0]))),\r\n",
    "                                                                cam(tensor2numpy(fake_A2B2A_heatmap[0]), self.img_size),\r\n",
    "                                                                RGB2BGR(tensor2numpy(denorm(fake_A2B2A[0])))), 0)), 1)\r\n",
    "\r\n",
    "                    B2A = np.concatenate((B2A, np.concatenate((RGB2BGR(tensor2numpy(denorm(real_B[0]))),\r\n",
    "                                                                cam(tensor2numpy(fake_B2B_heatmap[0]), self.img_size),\r\n",
    "                                                                RGB2BGR(tensor2numpy(denorm(fake_B2B[0]))),\r\n",
    "                                                                cam(tensor2numpy(fake_B2A_heatmap[0]), self.img_size),\r\n",
    "                                                                RGB2BGR(tensor2numpy(denorm(fake_B2A[0]))),\r\n",
    "                                                                cam(tensor2numpy(fake_B2A2B_heatmap[0]), self.img_size),\r\n",
    "                                                                RGB2BGR(tensor2numpy(denorm(fake_B2A2B[0])))), 0)), 1)\r\n",
    "\r\n",
    "                cv2.imwrite(os.path.join(self.result_dir, self.dataset, 'img', 'A2B_%07d.png' % step), A2B * 255.0)\r\n",
    "                cv2.imwrite(os.path.join(self.result_dir, self.dataset, 'img', 'B2A_%07d.png' % step), B2A * 255.0)\r\n",
    "                self.genA2B.train(), self.genB2A.train(), self.disGA.train(), self.disGB.train(), self.disLA.train(), self.disLB.train()\r\n",
    "            if step % self.save_freq == 0:\r\n",
    "                self.save(os.path.join(self.result_dir, self.dataset, 'model'), step)\r\n",
    "\r\n",
    "            if step % 1000 == 0:\r\n",
    "                fluid.save_dygraph(self.genA2B.state_dict(),\r\n",
    "                                    os.path.join(self.result_dir, self.dataset + \"/latest/new/genA2B\"))\r\n",
    "                fluid.save_dygraph(self.genB2A.state_dict(),\r\n",
    "                                    os.path.join(self.result_dir, self.dataset + \"/latest/new/genB2A\"))\r\n",
    "                fluid.save_dygraph(self.disGA.state_dict(),\r\n",
    "                                    os.path.join(self.result_dir, self.dataset + \"/latest/new/disGA\"))\r\n",
    "                fluid.save_dygraph(self.disGB.state_dict(),\r\n",
    "                                    os.path.join(self.result_dir, self.dataset + \"/latest/new/disGB\"))\r\n",
    "                fluid.save_dygraph(self.disLA.state_dict(),\r\n",
    "                                    os.path.join(self.result_dir, self.dataset + \"/latest/new/disLA\"))\r\n",
    "                fluid.save_dygraph(self.disLB.state_dict(),\r\n",
    "                                    os.path.join(self.result_dir, self.dataset + \"/latest/new/disLB\"))\r\n",
    "                fluid.save_dygraph(self.D_optim.state_dict(),\r\n",
    "                                    os.path.join(self.result_dir, self.dataset + \"/latest/new/D_optim\"))\r\n",
    "                fluid.save_dygraph(self.G_optim.state_dict(),\r\n",
    "                                    os.path.join(self.result_dir, self.dataset + \"/latest/new/G_optim\"))\r\n",
    "                fluid.save_dygraph(self.genA2B.state_dict(),\r\n",
    "                                    os.path.join(self.result_dir, self.dataset + \"/latest/new/D_optim\"))\r\n",
    "                fluid.save_dygraph(self.genB2A.state_dict(),\r\n",
    "                                    os.path.join(self.result_dir, self.dataset + \"/latest/new/G_optim\"))\r\n",
    "\r\n",
    "    def save(self, result_dir, step):\r\n",
    "        fluid.save_dygraph(self.genA2B.state_dict(), os.path.join(result_dir, \"{}/genA2B\".format(step)))\r\n",
    "        fluid.save_dygraph(self.genB2A.state_dict(), os.path.join(result_dir, \"{}/genB2A\".format(step)))\r\n",
    "        fluid.save_dygraph(self.disGA.state_dict(), os.path.join(result_dir, \"{}/disGA\".format(step)))\r\n",
    "        fluid.save_dygraph(self.disGB.state_dict(), os.path.join(result_dir, \"{}/disGB\".format(step)))\r\n",
    "        fluid.save_dygraph(self.disLA.state_dict(), os.path.join(result_dir, \"{}/disLA\".format(step)))\r\n",
    "        fluid.save_dygraph(self.disLB.state_dict(), os.path.join(result_dir, \"{}/disLB\".format(step)))\r\n",
    "        fluid.save_dygraph(self.genA2B.state_dict(), os.path.join(result_dir, \"{}/D_optim\".format(step)))\r\n",
    "        fluid.save_dygraph(self.genB2A.state_dict(), os.path.join(result_dir, \"{}/G_optim\".format(step)))\r\n",
    "        fluid.save_dygraph(self.D_optim.state_dict(), os.path.join(result_dir, \"{}/D_optim\".format(step)))\r\n",
    "        fluid.save_dygraph(self.G_optim.state_dict(), os.path.join(result_dir, \"{}/G_optim\".format(step)))\r\n",
    "\r\n",
    "    def load(self, dir, step):\r\n",
    "        genA2B, _ = fluid.load_dygraph(os.path.join(dir, \"{}/genA2B\".format(step)))\r\n",
    "        genB2A, _ = fluid.load_dygraph(os.path.join(dir, \"{}/genB2A\".format(step)))\r\n",
    "        disGA, _ = fluid.load_dygraph(os.path.join(dir, \"{}/disGA\".format(step)))\r\n",
    "        disGB, _ = fluid.load_dygraph(os.path.join(dir, \"{}/disGB\".format(step)))\r\n",
    "        disLA, _ = fluid.load_dygraph(os.path.join(dir, \"{}/disLA\".format(step)))\r\n",
    "        disLB, _ = fluid.load_dygraph(os.path.join(dir, \"{}/disLB\".format(step)))\r\n",
    "        _, D_optim = fluid.load_dygraph(os.path.join(dir, \"{}/D_optim\".format(step)))\r\n",
    "        _, G_optim = fluid.load_dygraph(os.path.join(dir, \"{}/G_optim\".format(step)))\r\n",
    "        self.genA2B.load_dict(genA2B)\r\n",
    "        self.genB2A.load_dict(genB2A)\r\n",
    "        self.disGA.load_dict(disGA)\r\n",
    "        self.disGB.load_dict(disGB)\r\n",
    "        self.disLA.load_dict(disLA)\r\n",
    "        self.disLB.load_dict(disLB)\r\n",
    "        self.G_optim.set_dict(G_optim)\r\n",
    "        self.D_optim.set_dict(D_optim)\r\n",
    "\r\n",
    "    def test(self):\r\n",
    "        model_list = os.listdir(os.path.join(self.result_dir, self.dataset, 'model'))\r\n",
    "        if not len(model_list) == 0:\r\n",
    "\r\n",
    "            model_list.sort()\r\n",
    "            iter = int(model_list[-1])\r\n",
    "            self.load(os.path.join(self.result_dir, self.dataset, 'model'), iter)\r\n",
    "            print(\"[*] Load SUCCESS\")\r\n",
    "        else:\r\n",
    "            print(\"[*] Load FAILURE\")\r\n",
    "            return\r\n",
    "\r\n",
    "        self.genA2B.eval(), self.genB2A.eval()\r\n",
    "        for n, (real_A, _) in enumerate(self.testA_loader()):\r\n",
    "\r\n",
    "            real_A = np.array([real_A.reshape(3, 256, 256)]).astype(\"float32\")\r\n",
    "\r\n",
    "            real_A = to_variable(real_A)\r\n",
    "\r\n",
    "            fake_A2B, _, fake_A2B_heatmap = self.genA2B(real_A)\r\n",
    "\r\n",
    "            fake_A2B2A, _, fake_A2B2A_heatmap = self.genB2A(fake_A2B)\r\n",
    "\r\n",
    "            fake_A2A, _, fake_A2A_heatmap = self.genB2A(real_A)\r\n",
    "\r\n",
    "            A2B = np.concatenate(\r\n",
    "                (RGB2BGR(tensor2numpy(denorm(real_A[0]))), cam(tensor2numpy(fake_A2A_heatmap[0]), self.img_size),\r\n",
    "                    RGB2BGR(tensor2numpy(denorm(fake_A2A[0]))), cam(tensor2numpy(fake_A2B_heatmap[0]), self.img_size),\r\n",
    "                    RGB2BGR(tensor2numpy(denorm(fake_A2B[0]))),\r\n",
    "                    cam(tensor2numpy(fake_A2B2A_heatmap[0]), self.img_size),\r\n",
    "                    RGB2BGR(tensor2numpy(denorm(fake_A2B2A[0])))), 0)\r\n",
    "\r\n",
    "            cv2.imwrite(os.path.join(self.result_dir, self.dataset, 'test', 'A2B_%d.png' % (n + 1)), A2B * 255.0)\r\n",
    "\r\n",
    "        for n, (real_B, _) in enumerate(self.testB_loader()):\r\n",
    "\r\n",
    "            real_B = np.array([real_B.reshape(3, 256, 256)]).astype(\"float32\")\r\n",
    "\r\n",
    "            real_B = to_variable(real_B)\r\n",
    "\r\n",
    "            fake_B2A, _, fake_B2A_heatmap = self.genB2A(real_B)\r\n",
    "\r\n",
    "            fake_B2A2B, _, fake_B2A2B_heatmap = self.genA2B(fake_B2A)\r\n",
    "\r\n",
    "            fake_B2B, _, fake_B2B_heatmap = self.genA2B(real_B)\r\n",
    "\r\n",
    "            B2A = np.concatenate(\r\n",
    "                (RGB2BGR(tensor2numpy(denorm(real_B[0]))), cam(tensor2numpy(fake_B2B_heatmap[0]), self.img_size),\r\n",
    "                    RGB2BGR(tensor2numpy(denorm(fake_B2B[0]))), cam(tensor2numpy(fake_B2A_heatmap[0]), self.img_size),\r\n",
    "                    RGB2BGR(tensor2numpy(denorm(fake_B2A[0]))),\r\n",
    "                    cam(tensor2numpy(fake_B2A2B_heatmap[0]), self.img_size),\r\n",
    "                    RGB2BGR(tensor2numpy(denorm(fake_B2A2B[0])))), 0)\r\n",
    "\r\n",
    "            cv2.imwrite(os.path.join(self.result_dir, self.dataset, 'test', 'B2A_%d.png' % (n + 1)), B2A * 255.0)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "    def test_change(self):\r\n",
    "        model_list = os.listdir(os.path.join(self.result_dir, self.dataset, 'model'))\r\n",
    "        if not len(model_list) == 0:\r\n",
    "            model_list.sort()\r\n",
    "            iter = int(model_list[-1].split('/')[-1])\r\n",
    "            self.load(os.path.join(self.result_dir, self.dataset, 'model'), iter)\r\n",
    "            print(\"[*] Load SUCCESS\")\r\n",
    "        else:\r\n",
    "            print(\"[*] Load FAILURE\")\r\n",
    "            return\r\n",
    "\r\n",
    "        self.genA2B.eval(), self.genB2A.eval()\r\n",
    "        for n, (real_A, fname) in enumerate(self.testA_loader()):\r\n",
    "            real_A = np.array([real_A[0].reshape(3, 256, 256)]).astype(\"float32\")\r\n",
    "            real_A = to_variable(real_A)\r\n",
    "            fake_A2B, _, _ = self.genA2B(real_A)\r\n",
    "\r\n",
    "            A2B = RGB2BGR(tensor2numpy(denorm(fake_A2B[0])))\r\n",
    "\r\n",
    "            cv2.imwrite(os.path.join(self.result_dir, self.dataset,'test', 'testA2B', '%s_fake.%s' % (fname.split('.')[0],fname.split('.')[-1])),\r\n",
    "                        A2B * 255.0)\r\n",
    "\r\n",
    "        for n, (real_B, fname) in enumerate(self.testB_loader()):\r\n",
    "            real_B = np.array([real_B[0].reshape(3, 256, 256)]).astype(\"float32\")\r\n",
    "            real_B = to_variable(real_B)\r\n",
    "            fake_B2A, _, _ = self.genB2A(real_B)\r\n",
    "\r\n",
    "            B2A = RGB2BGR(tensor2numpy(denorm(fake_B2A[0])))\r\n",
    "\r\n",
    "            cv2.imwrite(os.path.join(self.result_dir, self.dataset,'test', 'testB2A', '%s_fake.%s' % (fname.split('.')[0],fname.split('.')[-1])),\r\n",
    "                        B2A * 255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/\n",
      "Collecting paddlepaddle-gpu==1.8.3.post97\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/20/74/8222e774dcf935a75f5ed765c8a635d08e67ac8d036a131928a5ddccd787/paddlepaddle_gpu-1.8.3.post97-cp37-cp37m-manylinux1_x86_64.whl (404.9MB)\n",
      "\u001b[K     |████████████████████████████████| 404.9MB 19.2MB/s eta 0:00:01     |███████████▏                    | 141.8MB 8.0MB/s eta 0:00:34     |█████████████████▋              | 223.1MB 8.0MB/s eta 0:00:23\n",
      "\u001b[?25hRequirement already satisfied: gast>=0.3.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.8.3.post97) (0.3.3)\n",
      "Requirement already satisfied: nltk; python_version >= \"3.5\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.8.3.post97) (3.4.5)\n",
      "Requirement already satisfied: six in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.8.3.post97) (1.15.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.8.3.post97) (4.4.0)\n",
      "Requirement already satisfied: funcsigs in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.8.3.post97) (1.0.2)\n",
      "Requirement already satisfied: protobuf>=3.1.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.8.3.post97) (3.12.2)\n",
      "Requirement already satisfied: scipy<=1.3.1; python_version >= \"3.5\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.8.3.post97) (1.3.0)\n",
      "Requirement already satisfied: requests>=2.20.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.8.3.post97) (2.22.0)\n",
      "Requirement already satisfied: graphviz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.8.3.post97) (0.13)\n",
      "Requirement already satisfied: Pillow in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.8.3.post97) (7.1.2)\n",
      "Requirement already satisfied: prettytable in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.8.3.post97) (0.7.2)\n",
      "Requirement already satisfied: pathlib in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.8.3.post97) (1.0.1)\n",
      "Requirement already satisfied: matplotlib; python_version >= \"3.6\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.8.3.post97) (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.12; python_version >= \"3.5\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.8.3.post97) (1.16.4)\n",
      "Requirement already satisfied: objgraph in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.8.3.post97) (3.4.1)\n",
      "Requirement already satisfied: rarfile in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.8.3.post97) (3.1)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.8.3.post97) (4.1.1.26)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.8.3.post97) (5.1.2)\n",
      "Requirement already satisfied: astor in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.8.3.post97) (0.8.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from protobuf>=3.1.0->paddlepaddle-gpu==1.8.3.post97) (41.4.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.20.0->paddlepaddle-gpu==1.8.3.post97) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.20.0->paddlepaddle-gpu==1.8.3.post97) (2019.9.11)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.20.0->paddlepaddle-gpu==1.8.3.post97) (1.25.6)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.20.0->paddlepaddle-gpu==1.8.3.post97) (2.8)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib; python_version >= \"3.6\"->paddlepaddle-gpu==1.8.3.post97) (2.4.2)\n",
      "Requirement already satisfied: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib; python_version >= \"3.6\"->paddlepaddle-gpu==1.8.3.post97) (2019.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib; python_version >= \"3.6\"->paddlepaddle-gpu==1.8.3.post97) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib; python_version >= \"3.6\"->paddlepaddle-gpu==1.8.3.post97) (2.8.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib; python_version >= \"3.6\"->paddlepaddle-gpu==1.8.3.post97) (1.1.0)\n",
      "Installing collected packages: paddlepaddle-gpu\n",
      "  Found existing installation: paddlepaddle-gpu 1.8.0.post97\n",
      "    Uninstalling paddlepaddle-gpu-1.8.0.post97:\n",
      "      Successfully uninstalled paddlepaddle-gpu-1.8.0.post97\n",
      "Successfully installed paddlepaddle-gpu-1.8.3.post97\n"
     ]
    }
   ],
   "source": [
    "# 1.升级版本\r\n",
    "!pip install paddlepaddle-gpu==1.8.3.post97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 2.解压数据集\r\n",
    "!unzip -q /home/aistudio/data/data48778/308470_627400_bundle_archive.zip -d data/datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['trainB', 'trainA', 'testB', 'testA']\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# 3.生成相应训练集和测试集的txt\r\n",
    "!python genarate_txt.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 4.训练 训练并保存模型\r\n",
    "!export LD_LIBRARY_PATH=/usr/local/cuda-9.2/lib64:$LD_LIBRARY_PATH && python main.py --dataset datasets --phase train --iteration 20000 --print_freq 2000 --save_freq 5000  --light True --resume True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0906 00:33:26.866027  4124 device_context.cc:252] Please NOTE: device: 0, CUDA Capability: 70, Driver API Version: 9.2, Runtime API Version: 9.0\n",
      "W0906 00:33:26.871320  4124 device_context.cc:260] device: 0, cuDNN Version: 7.6.\n",
      "[*] Load SUCCESS\n",
      "[*] Test finished!\n"
     ]
    }
   ],
   "source": [
    "# 5.测试示例 测试转换对比，原图，注意力图，转换图等\r\n",
    "!export LD_LIBRARY_PATH=/usr/local/cuda-9.2/lib64:$LD_LIBRARY_PATH && python main.py --phase test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0905 19:47:36.823904 26838 device_context.cc:252] Please NOTE: device: 0, CUDA Capability: 70, Driver API Version: 9.2, Runtime API Version: 9.0\n",
      "W0905 19:47:36.829147 26838 device_context.cc:260] device: 0, cuDNN Version: 7.6.\n",
      "['.ipynb_checkpoints', '278', '283', '288', '293', '298', '303']\n",
      "[*] Load SUCCESS\n",
      "[*] Test_change finished!\n"
     ]
    }
   ],
   "source": [
    "# 6.测试 转换test对应的fake图像并单独存储\r\n",
    "!export LD_LIBRARY_PATH=/usr/local/cuda-9.2/lib64:$LD_LIBRARY_PATH && python main.py --phase test_change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 1.8.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
